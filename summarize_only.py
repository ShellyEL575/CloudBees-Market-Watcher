import os
import json
from datetime import datetime
from summarizer import generate_summary, extract_insights_from_social
from utils import group_posts_by_topic, write_report

# Load scraped posts
with open("data/raw_posts.json", "r") as f:
    posts = json.load(f)

print("\nâœï¸ Generating summary...")

# Group posts by topic
grouped = group_posts_by_topic(posts)

print(f"ğŸš€ Product Updates: {len(grouped.get('ğŸš€ Product Updates', []))} posts")
print(f"ğŸ’¬ Social Buzz: {len(grouped.get('ğŸ’¬ Social Buzz', []))} posts")
print(f"ğŸ“ˆ Trends: {len(grouped.get('ğŸ“ˆ Trends', []))} posts")

# Generate summaries for each category
summary_sections = {
    "ğŸš€ Product Updates": generate_summary(grouped.get("ğŸš€ Product Updates", [])),
    "ğŸ’¬ Social Buzz": generate_summary(grouped.get("ğŸ’¬ Social Buzz", [])),
    "ğŸ“ˆ Trends": generate_summary(grouped.get("ğŸ“ˆ Trends", [])),
    "ğŸ§  Insights": extract_insights_from_social(grouped.get("ğŸ’¬ Social Buzz", []))
}

# Write markdown report
report_path = write_report(summary_sections)

# Print final summary
print("\n===== ğŸ“° Final Market Watch Report =====\n")
print(summary_sections["ğŸš€ Product Updates"])
print("\n## ğŸ’¬ Social Buzz")
print(summary_sections["ğŸ’¬ Social Buzz"])
print("\n## ğŸ“ˆ Trends")
print(summary_sections["ğŸ“ˆ Trends"])
print("\n## ğŸ§  Insights")
print(summary_sections["ğŸ§  Insights"])

print(f"\nâœ… Report written to {report_path}")
print("âœ… Summary report generated!")
