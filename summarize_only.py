import json
import os
from datetime import datetime
from summarizer import generate_summary, extract_insights_from_social
from utils import group_posts_by_topic, write_report
from exec_summary import generate_exec_summary

def extract_curated_source_list(posts):
    """
    Builds a clean list of unique (title, url) for exec summary.
    Avoids duplicates. Avoids HN comment URLs.
    """
    seen = set()
    curated = []

    for p in posts:
        title = p.get("title", "Untitled")
        url = p.get("url") or p.get("link")
        if not url:
            continue

        key = (title, url)
        if key not in seen:
            curated.append(key)
            seen.add(key)

    return curated


def main():
    print("âœï¸ Starting summarization...")

    with open("data/posts.json") as f:
        posts = json.load(f)

    print(f"âœ… Loaded {len(posts)} posts")

    print("ğŸ“Š Grouping...")
    grouped = group_posts_by_topic(posts)

    print("ğŸ§  Extracting insights...")
    insights = extract_insights_from_social(grouped.get("ğŸ’¬ Social Buzz", []))

    print("ğŸ“„ Building report sections...")
    sections = {
        "ğŸš€ Product Updates": generate_summary(grouped["ğŸš€ Product Updates"]),
        "ğŸ’¬ Social Buzz": generate_summary(grouped["ğŸ’¬ Social Buzz"]),
        "ğŸ“ˆ Trends": generate_summary(grouped["ğŸ“ˆ Trends"]),
        "ğŸ§  Insights": insights,
    }

    print("ğŸ“ Writing main report...")
    write_report(sections)

    print("ğŸ” Building curated source set...")
    curated_sources = extract_curated_source_list(posts)

    print("ğŸ“˜ Generating executive summary...")
    exec_md = generate_exec_summary(insights, curated_sources)

    os.makedirs("reports", exist_ok=True)
    exec_report_path = f"reports/exec_summary_{datetime.utcnow().strftime('%Y-%m-%d')}.md"
    with open(exec_report_path, "w", encoding="utf-8") as f:
        f.write(exec_md)

    print(f"âœ… Exec summary written to {exec_report_path}")


if __name__ == "__main__":
    main()
